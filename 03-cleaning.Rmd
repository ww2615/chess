# Data transformation

## Understanding the Raw Data

The raw data was in a zipped format of .pgn.bz2. The unzipped .pgn file was then converted through [read.py](code/read.py).

The result of this transformation was named "data_index.csv" each constituting 10,000,000 lines. Naturally, there were 9 files since the total count of games in the original data was 88,092,721.

**Each row** represented a **game** with columns.

This "data_index.csv" was only generated to answer the following questions.

- What items are missing in the original data?
- How many games were annotated?

The answer to the first question will be answered in the next chapter.
From the data, we deduced that 7,142,630 / 88,092,721 = **8.1 %** of the games were annotated compared to the **6 %** claimed on the [website](https://database.lichess.org/#standard_games).

## Formatting the Raw Data

We decided to focus on the **7,142,630** games that were annotated.

The first formatting process was done using [eval.py](code/eval.py).

This process was different from the read.py that the resulting csv(pgn_index.csv) from eval.py contained the PGN descriptions of every game played.

This process was conducted to generate a working **csv dataset** independent from the original data set.

The second formatting process used [edit.py](code/edit.py).

The formatting process intended to change **each row** to **moves** instead of **games**.


The missing data of this csv data set will be examined in the next chapter.

464,436,334 annotated moves have been played but this data set was impossible to work with. 

We decided to focus on the most popular time control format **600 + 0** or 10 minutes with no increment.

This time format is **16.91 %** of all games.

The [timecount.csv](data/timecount.csv) was generated through [count.py](code/count.py).


```{r, fig.width = 12, fig.height = 9}
defaultW <- getOption("warn") 
options(warn = -1) 
library(tidyverse)
library(weights)
dft <- read.csv("data/timecount.csv", check.names=FALSE)
dft <- gather(dft,TimeControl, count)
dft$count <- dft$count / sum(dft$count) * 100
dft <- arrange(dft, desc(count))
dft %>% slice(1:15) %>%
    ggplot(., aes(x=reorder(TimeControl, -count), y=count))+
              geom_bar(stat='identity', fill = "lightblue") +
  xlab("TimeControl") + 
  ylab("Percentage") + 
  scale_fill_brewer(palette="BuPu")
options(warn = defaultW)
```


By choosing this time format, we were able to conduct a deeper analysis of the relationship between time and bad moves.

## Crafting the Columns

When transforming the data to **moves_index.csv**, we selected and crafted columns to fit our analyses.
Since the **quality of moves** and **time** was the focus of our analysis, columns such as `UTCDate, UTCTime, White, and BlackRatingDiff` were removed.

Example Transformation)
1... c5 { [%clk 0:01:00] [%eval 0.00]} 2. Nf3 { [%clk 0:01:00] [%eval 0.00]} 2... d6? { [%clk 0:00:59] [%eval -1.00]}

Let's focus on 2...d6?

- **MoveNum**, **Color**, and **Move** was crafted by separating the strings `2... d6` to `2` `... = b`and `d6?`.
- **Type** was crafted by checking whether the move included `?`, `?!`, `??`, `!`, `!?`, and `!!`. 
   - The purpose of creating **Type** was to filter the variable to understand blunders.
- **Time** and **Eval** was the %clk and %eval on the move.
- **TimeSpent** and **EvalDiff** was generated by subtracting the values.
   - **TimeSpent** was the difference of time between **moves**(same color). ex) 0:00:01 between 1...c5 and 2...d6?
   - **EvalDiff** was the difference of evaluation between **turns**(opposite color). ex) -1.00 between 2. Nf3 and 2...d6?
   
These columns were also used in 600+0.csv.

## Focusing on 600+0 data

We can run a weighted t-test and chi-square test on the Elo of players

Both results show that the **mean** of both data is the same and the data are **dependent**

The [elocount.csv](data/elocount.csv) and [elo600count.csv](data/elo600count.csv)  was generated through [count.py](code/count.py).
```{r}
defaultW <- getOption("warn") 
options(warn = -1)

library(tidyverse)
library(quantreg)
library(RColorBrewer)
library(hrbrthemes)
library(weights)

df0 <- read.csv("data/elocount.csv", check.names=FALSE)
df0 <- gather(df0, elo, count)
df0$elo = as.integer(df0$elo)

df0$elo <- as.integer(df0$elo)
df0 <- filter(df0, elo > 500)
df0$elo <- df0$elo + 50

df1 <- read.csv("data/elo600count.csv", check.names = FALSE)
df1 <- gather(df1, elo, count)
df1$elo <- as.integer(df1$elo)
df1 <- filter(df1, elo > 500)
df1$elo <- df1$elo + 50
df0$elo600 <- df1$count

wtd.t.test(df0$elo, df1$elo, df0$count, df1$count)
chisq.test(df0$count, df1$count)
options(warn = defaultW)
```

The following are the histogram and boxplots of the Elo distribution of all annotated games compared to 600+0 annotated games.

```{r, fig.width = 12, fig.height = 9}
df0$count <- df0$count / sum(df0$count)
df0$elo600 <- df0$elo600 / sum(df0$elo600)
df2 <- df0 %>% gather(colname, count, -elo)
colnames(df2) <- c("elo", "type", "percent")
df2 <- df2 %>%                               
  mutate(type = replace(type, type == "count", "All Annotated Games"))
df2 <- df2 %>%                               
  mutate(type = replace(type, type == "elo600", "600+0 Games"))
ggplot(df2, aes(x = elo, y = percent, fill = type)) + 
  geom_bar(alpha = 0.6, stat = "identity", position = "identity")
ggplot(df2, aes(x = factor(type), y = elo, weight = percent)) + 
  geom_boxplot(width = 0.6) +
  xlab("Type of Games") +
  scale_fill_brewer(palette="BuPu")

```

It is clear that 600+0 is a good representation of the players playing in lichess.org.
The analysis will be based on the more manageable 600+0 dataset.